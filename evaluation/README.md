# ğŸ“Š DiretÃ³rio: Evaluation

## PropÃ³sito

Este diretÃ³rio contÃ©m scripts, mÃ©tricas e anÃ¡lises para avaliar a qualidade dos modelos gerados, comparando abordagens baseline e interativa.

## Estrutura Sugerida

```
evaluation/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ completeness_calculator.py
â”‚   â”œâ”€â”€ conformance_validator.py
â”‚   â””â”€â”€ question_quality_analyzer.py
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ quantitative_results.csv
â”‚   â”œâ”€â”€ qualitative_results.json
â”‚   â””â”€â”€ comparison_tables/
â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ completeness_comparison.png
â”‚   â”œâ”€â”€ conformance_scores.png
â”‚   â””â”€â”€ question_analysis.png
â”œâ”€â”€ expert_evaluations/
â”‚   â”œâ”€â”€ evaluator_1_results.json
â”‚   â”œâ”€â”€ evaluator_2_results.json
â”‚   â””â”€â”€ consensus_analysis.json
â””â”€â”€ reports/
    â””â”€â”€ evaluation_summary.md
```

## Uso no Ciclo de Vida do Projeto

### Fase 1: PreparaÃ§Ã£o
- Definir mÃ©tricas a serem calculadas
- Criar scripts de cÃ¡lculo automÃ¡tico
- Preparar formulÃ¡rios para avaliaÃ§Ã£o de especialistas

### Fase 2: ExecuÃ§Ã£o
- Calcular mÃ©tricas quantitativas
- Coletar avaliaÃ§Ãµes de especialistas
- Processar dados brutos

### Fase 3: AnÃ¡lise
- Comparar abordagens baseline vs. interativa
- Identificar padrÃµes e correlaÃ§Ãµes
- Gerar visualizaÃ§Ãµes

### Fase 4: ConsolidaÃ§Ã£o
- Criar tabelas comparativas
- Preparar relatÃ³rio de avaliaÃ§Ã£o
- Documentar conclusÃµes

## MÃ©tricas Implementadas

### 1. Completude (Completeness)
- **Cobertura de Atores**: % de atores identificados vs. esperado
- **Cobertura de Metas**: % de metas identificadas vs. esperado
- **Cobertura de Softgoals**: % de softgoals identificados vs. esperado
- **Cobertura de Tarefas**: % de tarefas identificadas vs. esperado
- **Cobertura de DependÃªncias**: % de dependÃªncias identificadas vs. esperado

### 2. Conformidade (Conformance)
- **ValidaÃ§Ã£o Estrutural**: Conformidade com schema JSON
- **ValidaÃ§Ã£o de Tipos**: Tipos corretos de elementos
- **Integridade Referencial**: IDs vÃ¡lidos e referÃªncias corretas
- **Conformidade iStar 2.0**: AderÃªncia Ã  especificaÃ§Ã£o da notaÃ§Ã£o

### 3. Qualidade das Perguntas (Interactive Only)
- **NÃºmero de Perguntas**: Quantidade gerada
- **CategorizaÃ§Ã£o**: DistribuiÃ§Ã£o por tipo (atores, metas, etc.)
- **RelevÃ¢ncia**: AvaliaÃ§Ã£o manual de utilidade
- **Especificidade**: QuÃ£o especÃ­ficas sÃ£o as perguntas

## AvaliaÃ§Ã£o por Especialistas

### CritÃ©rios Qualitativos
1. **Completude Percebida**: O modelo captura todos os elementos importantes?
2. **CorreÃ§Ã£o**: Os elementos estÃ£o corretos e bem definidos?
3. **Clareza**: O modelo Ã© fÃ¡cil de entender?
4. **Utilidade das Perguntas**: As perguntas ajudaram a melhorar o modelo?

### Processo
1. Especialistas avaliam modelos cegamente (sem saber a abordagem)
2. Avaliam em escala Likert (1-5)
3. Fornecem comentÃ¡rios qualitativos
4. Consenso Ã© calculado quando mÃºltiplos avaliadores

## Scripts de AnÃ¡lise

### CÃ¡lculo AutomÃ¡tico
- ComparaÃ§Ã£o de modelos gerados vs. gold standard
- CÃ¡lculo de mÃ©tricas de completude
- ValidaÃ§Ã£o de conformidade estrutural

### AnÃ¡lise Comparativa
- EstatÃ­sticas descritivas (mÃ©dia, desvio padrÃ£o)
- Testes estatÃ­sticos (se aplicÃ¡vel)
- VisualizaÃ§Ãµes comparativas

### Processamento de AvaliaÃ§Ãµes
- AgregaÃ§Ã£o de avaliaÃ§Ãµes de especialistas
- CÃ¡lculo de inter-avaliador agreement
- AnÃ¡lise de consenso

## VisualizaÃ§Ãµes

- GrÃ¡ficos de barras comparativos
- Heatmaps de completude
- DistribuiÃ§Ãµes de scores
- AnÃ¡lise de correlaÃ§Ãµes

## Notas

- MÃ©tricas quantitativas sÃ£o objetivas e reproduzÃ­veis
- AvaliaÃ§Ãµes qualitativas requerem mÃºltiplos avaliadores
- Resultados devem ser estatisticamente significativos (se possÃ­vel)
- Documentar limitaÃ§Ãµes das mÃ©tricas

